import os
import pandas as pd
from sqlalchemy import create_engine
from pathlib import Path
import logging
import sys

# Ajouter le r√©pertoire parent pour l'import des modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configuration de la base de donn√©es
DATABASE_URL = "postgresql://postgres:5456CopaS@localhost:5432/myapi_db"
engine = create_engine(DATABASE_URL)

def clean_database():
    """Nettoie la table family_employment avant l'import"""
    try:
        with engine.connect() as conn:
            logger.info("üóëÔ∏è Nettoyage de la table family_employment...")
            conn.execute("TRUNCATE TABLE family_employment RESTART IDENTITY CASCADE")
            logger.info("‚úÖ Table nettoy√©e avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du nettoyage de la table : {str(e)}")
        raise

def import_data(year, file_path):
    """Importe les donn√©es d'un fichier CSV pour une ann√©e sp√©cifique"""
    try:
        logger.info(f"üìä Chargement des donn√©es pour {year} depuis {file_path}...")

        # V√©rifier que le fichier existe
        if not os.path.exists(file_path):
            logger.error(f"‚ùå Fichier non trouv√©: {file_path}")
            return 0

        # Charger le fichier CSV
        df = pd.read_csv(
            file_path,
            delimiter=";",
            encoding="utf-8",
            dtype={"CODGEO": str, "AGEFOR5": int, "TF12": int, "NB": float}
        )

        logger.info(f"üìà Donn√©es charg√©es: {len(df)} lignes")

        # V√©rifier que les colonnes n√©cessaires sont pr√©sentes
        required_columns = ["CODGEO", "AGEFOR5", "TF12", "NB"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"‚ùå Colonnes manquantes dans le fichier: {missing_columns}")
            return 0

        # Nettoyage des donn√©es
        df = df.dropna(subset=required_columns)
        logger.info(f"üßπ Apr√®s nettoyage: {len(df)} lignes valides")

        # Insertion par lots (batch) pour de meilleures performances
        batch_size = 5000
        total_records = 0

        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            records = []

            for _, row in batch.iterrows():
                record = {
                    'geo_code': str(row["CODGEO"]),
                    'year': year,
                    'age_group': int(row["AGEFOR5"]),
                    'tf12': int(row["TF12"]),
                    'number': float(row["NB"])
                }
                records.append(record)

            # Ins√©rer le lot en base
            with engine.begin() as conn:  # Transaction automatique
                conn.execute(
                    """
                    INSERT INTO family_employment
                    (geo_code, year, age_group, tf12, number)
                    VALUES (%(geo_code)s, %(year)s, %(age_group)s, %(tf12)s, %(number)s)
                    """,
                    records
                )

            total_records += len(records)
            logger.info(f"üîÑ Progression: {total_records}/{len(df)} enregistrements ins√©r√©s")

        logger.info(f"‚úÖ Import√© {total_records} enregistrements pour {year}")
        return total_records

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'importation des donn√©es pour {year}: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return 0

def import_family_employment_data():
    """Fonction principale d'importation des donn√©es d'emploi des familles"""
    try:
        # Nettoyer la base avant import
        clean_database()

        # Configuration des ann√©es et fichiers disponibles
        data_path = Path("data/families/family_employment")

        # Construction d'un dictionnaire dynamique des ann√©es disponibles
        available_data = {}

        # Chercher les fichiers existants qui suivent le format TD_FAM6v2_YYYY.csv
        for file_path in data_path.glob("TD_FAM6v2_*.csv"):
            try:
                # Extraire l'ann√©e du nom de fichier
                year_str = file_path.stem.split('_')[-1]
                year = int(year_str)
                available_data[year] = file_path
                logger.info(f"üìÅ Trouv√© fichier pour l'ann√©e {year}: {file_path}")
            except (ValueError, IndexError):
                logger.warning(f"‚ö†Ô∏è Format de nom de fichier non reconnu: {file_path}")

        if not available_data:
            logger.error("‚ùå Aucun fichier de donn√©es trouv√©")
            return

        # Importer chaque ann√©e disponible
        total_imported = 0
        for year, file_path in sorted(available_data.items()):
            count = import_data(year, file_path)
            total_imported += count

        logger.info(f"‚ú® Import termin√©. Total: {total_imported} enregistrements pour {len(available_data)} ann√©es")

    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©rale lors de l'importation: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    logger.info("üöÄ D√©marrage de l'import des donn√©es d'emploi des familles")
    import_family_employment_data()
    logger.info("üèÅ Import termin√©")
