import sys
import os
import pandas as pd
from pathlib import Path
import logging
import sqlalchemy as sa

# Ajouter le r√©pertoire racine du projet au chemin d'importation
# Cette ligne doit √™tre avant toute tentative d'importation des modules app
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import des modules app (load_dotenv est d√©j√† appel√© par app.database)
from app.database import engine, Base, SessionLocal
from app.models import Historical

def clean_database():
    """Nettoie la table historical"""
    try:
        with engine.connect() as conn:
            metadata = sa.MetaData()
            # V√©rifier si la table existe
            inspector = sa.inspect(engine)
            if 'historical' in inspector.get_table_names():
                logger.info("üóëÔ∏è Suppression de la table historical existante...")
                conn.execute(sa.text("DROP TABLE historical CASCADE"))
                logger.info("‚úÖ Table supprim√©e avec succ√®s")
            else:
                logger.info("‚ÑπÔ∏è Aucune table historical √† supprimer")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du nettoyage de la base : {str(e)}")
        raise

def create_historical_table():
    """Cr√©e la table historical avec SQLAlchemy"""
    try:
        with engine.connect() as conn:
            logger.info("üîß Cr√©ation de la table historical...")

            # Cr√©ation de la table en utilisant le mod√®le SQLAlchemy
            Historical.__table__.create(engine)
            logger.info("‚úÖ Table historical cr√©√©e")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la cr√©ation de la table : {str(e)}")
        raise

def import_historical_data():
    try:
        # Nettoyer la base d'abord
        clean_database()

        # Cr√©er la table historical
        create_historical_table()

        # V√©rifier le fichier
        file_path = Path("data/base-cc-serie-historique-2021.csv")
        if not file_path.exists():
            logger.error(f"‚ùå Fichier non trouv√© : {file_path}")
            return
        logger.info(f"‚úÖ Fichier trouv√© : {file_path}")

        # Charger les donn√©es
        logger.info("üìä Chargement des donn√©es historiques...")
        df = pd.read_csv(
            file_path,
            delimiter=";",
            encoding="utf-8",
            low_memory=False
        )

        # Pr√©parer les donn√©es
        logger.info("üîÑ Pr√©paration des donn√©es pour l'import...")
        records = []
        for _, row in df.iterrows():
            record = {
                'codgeo': row['CODGEO'],
                'pop_1968': float(row['D68_POP']) if 'D68_POP' in row and pd.notna(row['D68_POP']) else None,
                'pop_1975': float(row['D75_POP']) if 'D75_POP' in row and pd.notna(row['D75_POP']) else None,
                'pop_1982': float(row['D82_POP']) if 'D82_POP' in row and pd.notna(row['D82_POP']) else None,
                'pop_1990': float(row['D90_POP']) if 'D90_POP' in row and pd.notna(row['D90_POP']) else None,
                'pop_1999': float(row['D99_POP']) if 'D99_POP' in row and pd.notna(row['D99_POP']) else None,
                'pop_2010': float(row['P10_POP']) if 'P10_POP' in row and pd.notna(row['P10_POP']) else None,
                'pop_2015': float(row['P15_POP']) if 'P15_POP' in row and pd.notna(row['P15_POP']) else None,
                'pop_2021': float(row['P21_POP']) if 'P21_POP' in row and pd.notna(row['P21_POP']) else None
            }
            records.append(record)

        # Ins√©rer les donn√©es en utilisant SQLAlchemy
        logger.info("üíæ Insertion des donn√©es en base...")
        session = SessionLocal()
        try:
            # Option 1: Insertion par lots avec bulk_save_objects
            historical_objects = [Historical(**record) for record in records]
            session.bulk_save_objects(historical_objects)
            session.commit()

            # Option 2: Alternative avec bulk_insert_mappings
            # session.bulk_insert_mappings(Historical, records)
            # session.commit()

            logger.info(f"‚ú® Import termin√© avec succ√®s : {len(records)} enregistrements import√©s")
        except Exception as e:
            session.rollback()
            logger.error(f"‚ùå Erreur lors de l'insertion des donn√©es : {str(e)}")
            raise
        finally:
            session.close()

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'importation : {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    logger.info("üöÄ D√©marrage de l'import des donn√©es historiques")
    import_historical_data()
    logger.info("üèÅ Import termin√©")
